{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervision de la dérive de données\n",
        "\n",
        "Au fil du temps, des modèles peuvent devenir moins efficaces pour effectuer des prédictions précises en raison de la modification de tendances dans les données de caractéristiques. Ce phénomène est appelé *dérive de données*, et il est important de superviser votre solution d’apprentissage automatique pour le détecter de façon à pouvoir ré-effectuer l’apprentissage de vos modèles si nécessaire.\n",
        "\n",
        "Dans ce labo, vous allez configurer la supervision de la dérive de données pour les jeux de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avant de commencer\n",
        "\n",
        "En plus de la dernière version des packages **azureml-SDK** et **azureml-widgets**, vous aurez besoin du package **azureml-datadrift** pour exécuter le code contenu dans ce notebook. Exécutez la cellule ci-dessous pour vérifier qu’il est installé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip show azureml-datadrift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vous connecter à votre espace de travail\n",
        "\n",
        "Une fois les packages requis du Kit de développement logiciel (SDK) installés, vous êtes prêt à vous connecter à votre espace de travail.\n",
        "\n",
        "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649368594272
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to work with', ws.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer un jeu de données *base de référence*\n",
        "\n",
        "Pour superviser un jeu de données en lien avec la dérive de données, vous devez inscrire un jeu de données *base de référence* (généralement le jeu de données utilisé pour l’apprentissage de votre modèle) à utiliser comme point de comparaison avec des données collectées à l’avenir. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Datastore, Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "# Upload the baseline data\n",
        "default_ds = ws.get_default_datastore()\n",
        "Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )\n",
        "\n",
        "# Create and register the baseline dataset\n",
        "print('Registering baseline dataset...')\n",
        "baseline_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-baseline/*.csv'))\n",
        "baseline_data_set = baseline_data_set.register(workspace=ws, \n",
        "                           name='diabetes baseline',\n",
        "                           description='diabetes baseline data',\n",
        "                           tags = {'format':'CSV'},\n",
        "                           create_new_version=True)\n",
        "\n",
        "print('Baseline dataset registered!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer un jeu de données *cible*\n",
        "\n",
        "Au fil du temps, vous pourrez collecter de nouvelles données avec les mêmes caractéristiques que les données d’apprentissage de votre base de référence. Pour comparer ces nouvelles données aux données de base de référence, vous devez définir un ensemble de données cible incluant les caractéristiques que vous voulez analyser en lien avec la dérive des données, ainsi qu’un champ timestamp indiquant le moment où les nouvelles données étaient actuelles. Cela vous permettra de mesurer la dérive de données sur des intervalles temporels. Le timestamp peut être un champ dans le jeu de données lui-même, ou être dérivé du modèle de dossier et de nom de fichier utilisé pour stocker les données. Par exemple, vous pouvez stocker de nouvelles données dans une hiérarchie de dossiers qui se compose d’un dossier pour l’année, contenant un dossier pour le mois qui, à son tour, contient un dossier pour la journée. Vous pourriez simplement encoder l’année, le mois et le jour dans le nom de fichier comme suit : *data_2020-01-29.csv *. Telle est l’approche adoptée dans le code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "import pandas as pd\n",
        "\n",
        "print('Generating simulated data...')\n",
        "\n",
        "# Load the smaller of the two data files\n",
        "data = pd.read_csv('data/diabetes2.csv')\n",
        "\n",
        "# We'll generate data for the past 6 weeks\n",
        "weeknos = reversed(range(6))\n",
        "\n",
        "file_paths = []\n",
        "for weekno in weeknos:\n",
        "    \n",
        "    # Get the date X weeks ago\n",
        "    data_date = dt.date.today() - dt.timedelta(weeks=weekno)\n",
        "    \n",
        "    # Modify data to ceate some drift\n",
        "    data['Pregnancies'] = data['Pregnancies'] + 1\n",
        "    data['Age'] = round(data['Age'] * 1.2).astype(int)\n",
        "    data['BMI'] = data['BMI'] * 1.1\n",
        "    \n",
        "    # Save the file with the date encoded in the filename\n",
        "    file_path = 'data/diabetes_{}.csv'.format(data_date.strftime(\"%Y-%m-%d\"))\n",
        "    data.to_csv(file_path)\n",
        "    file_paths.append(file_path)\n",
        "\n",
        "# Upload the files\n",
        "path_on_datastore = 'diabetes-target'\n",
        "default_ds.upload_files(files=file_paths,\n",
        "                       target_path=path_on_datastore,\n",
        "                       overwrite=True,\n",
        "                       show_progress=True)\n",
        "\n",
        "# Use the folder partition format to define a dataset with a 'date' timestamp column\n",
        "partition_format = path_on_datastore + '/diabetes_{date:yyyy-MM-dd}.csv'\n",
        "target_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, path_on_datastore + '/*.csv'),\n",
        "                                                       partition_format=partition_format)\n",
        "\n",
        "# Register the target dataset\n",
        "print('Registering target dataset...')\n",
        "target_data_set = target_data_set.with_timestamp_columns('date').register(workspace=ws,\n",
        "                                                                          name='diabetes target',\n",
        "                                                                          description='diabetes target data',\n",
        "                                                                          tags = {'format':'CSV'},\n",
        "                                                                          create_new_version=True)\n",
        "\n",
        "print('Target dataset registered!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer un superviseur de dérive de données\n",
        "\n",
        "Vous êtes maintenant prêt à créer un superviseur de dérive de données pour les données de diabète. Le superviseur de dérive de données s’exécutera périodiquement ou à la demande pour comparer le jeu de données base de référence avec le jeu de données cible, auquel de nouvelles données seront ajoutées au fil du temps.\n",
        "\n",
        "### Créer une cible de calcul\n",
        "\n",
        "Pour exécuter le superviseur de dérive de données, vous aurez besoin d’une cible de calcul. Exécutez la cellule suivante pour spécifier un cluster de calcul (s’il n’existe pas, il sera créé).\n",
        "\n",
        "> **Important** : remplacez *your-compute-cluster* par le nom de votre cluster de calcul dans le code ci-dessous avant de l’exécuter. Les noms de cluster doivent être des noms globalement uniques d’une longueur comprise entre 2 et 16 caractères. Les caractères valides sont les lettres, les chiffres et le tiret (-)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Remarque** : les clusters et instances de calcul sont basés sur des images de machines virtuelles Azure standard. Pour cet exercice, l’image *Standard_DS11_v2* est recommandée pour obtenir l’équilibre optimal entre coûts et performances. Si votre abonnement s’accompagne d’un quota qui ne couvre pas cette image, choisissez-en une autre. Gardez cependant à l’esprit qu’une image plus grande peut entraîner des coûts plus élevés, tandis qu’une plus petite risque de ne pas suffire pour effectuer les tâches. Vous pouvez également demander à votre administrateur Azure d’étendre votre quota.\n",
        "\n",
        "### Définir le superviseur de dérive de données\n",
        "\n",
        "Vous êtes maintenant prêt à utiliser une classe **DataDriftDetector** afin de définir le superviseur de dérive des données pour vos données. Vous pouvez spécifier les caractéristiques que vous souhaitez superviser pour la dérive des données, le nom de la cible de calcul à utiliser pour exécuter le processus de supervision, la fréquence à laquelle les données doivent être comparées, le seuil de dérive de données au-delà duquel une alerte devrait être déclenchée et la latence (en heures) pour autoriser la collecte de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.datadrift import DataDriftDetector\n",
        "\n",
        "# set up feature list\n",
        "features = ['Pregnancies', 'Age', 'BMI']\n",
        "\n",
        "# set up data drift detector\n",
        "monitor = DataDriftDetector.create_from_datasets(ws, 'mslearn-diabates-drift', baseline_data_set, target_data_set,\n",
        "                                                      compute_target=cluster_name, \n",
        "                                                      frequency='Week', \n",
        "                                                      feature_list=features, \n",
        "                                                      drift_threshold=.3, \n",
        "                                                      latency=24)\n",
        "monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Renvoi du superviseur de dérive de données\n",
        "\n",
        "Vous disposez d’un jeu de données base de référence et d’un jeu de données cible incluant la collecte hebdomadaire simulée de données pour une période de six semaines. Vous pouvez l’utiliser pour renvoyer le superviseur afin qu’il puisse analyser la dérive de données entre la base de référence d’origine et les données cibles.\n",
        "\n",
        "> **Remarque** : l’exécution de cette opération peut prendre un certain temps, car la cible de calcul doit être démarrée pour exécuter l’analyse de renvoi. Il se peut que le widget ne puisse pas toujours se mettre à jour pour afficher l’état. Par conséquent, cliquez sur le lien pour observer l’état de l’expérience dans Azure Machine Learning studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "backfill = monitor.backfill(dt.datetime.now() - dt.timedelta(weeks=6), dt.datetime.now())\n",
        "\n",
        "RunDetails(backfill).show()\n",
        "backfill.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyser la dérive de données\n",
        "\n",
        "Vous pouvez utiliser le code suivant pour examiner la dérive de données pour les points dans le temps collectés dans l’exécution de renvoi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drift_metrics = backfill.get_metrics()\n",
        "for metric in drift_metrics:\n",
        "    print(metric, drift_metrics[metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez également visualiser les métriques de dérive de données dans [Azure Machine Learning Studio](https://ml.azure.com) en procédant comme suit :\n",
        "\n",
        "1. Sur la page **Données**, affichez l’onglet **Superviseurs de jeu de données**.\n",
        "2. Cliquez sur le superviseur de dérive de données que vous souhaitez afficher.\n",
        "3. Sélectionnez la plage de dates pour laquelle vous souhaitez afficher les mesures de dérive de données (si l’histogramme n’affiche pas plusieurs semaines de données, patientez une minute, puis cliquez sur **Actualiser**).\n",
        "4. Examinez les graphiques dans la section **Vue d’ensemble de la dérive** en haut, qui montre l’amplitude de la dérive globale et la contribution de la dérive par caractéristique.\n",
        "5. Explorez les graphiques dans la section **Détail de caractéristique** en bas, ce qui vous permet de voir diverses mesures de dérive pour des caractéristiques individuelles.\n",
        "\n",
        "> **Remarque** : pour vous aider à comprendre les métriques de dérive de données, consultez [Comment superviser des jeux de données](https://docs.microsoft.com/azure/machine-learning/how-to-monitor-datasets#understanding-data-drift-results) dans la documentation Azure Machine Learning.\n",
        "\n",
        "## Explorer davantage\n",
        "\n",
        "Ce labo est conçu pour vous présenter les concepts et principes de la supervision de la dérive des données. Pour en savoir plus sur la supervision de la dérive de données à l’aide de jeux de données, consultez [Détecter une dérive de données sur des jeux de données](https://docs.microsoft.com/azure/machine-learning/how-to-monitor-datasets) dans la documentation Azure Machine Learning.\n",
        "\n",
        "Vous pouvez également collecter des données à partir de services publiés, et les utiliser en tant que jeu de données cible pour la supervision de la dérive de données. Pour plus d’informations, consultez [Collecter des données à partir de modèles en production](https://docs.microsoft.com/azure/machine-learning/how-to-enable-data-collection).\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
