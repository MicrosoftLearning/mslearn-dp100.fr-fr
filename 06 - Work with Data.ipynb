{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utiliser des données\n",
        "\n",
        "Les données sont le fondement sur lequel les modèles d’apprentissage automatique sont construits. Le gestion des données de manière centralisée dans le cloud et leur accessibilité aux équipes de scientifiques des données qui exécutent des essais et des modèles d’apprentissage sur plusieurs stations de travail et cibles de calcul constituent une partie importante de toute solution professionnelle de science des données.\n",
        "\n",
        "Dans ce notebook, vous allez explorer deux objets Azure Machine Learning pour l’utilisation des données : *magasins de données* et *jeux de données*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vous connecter à votre espace de travail\n",
        "\n",
        "Pour commencer, connectez-vous à votre espace de travail.\n",
        "\n",
        "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366182180
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utiliser des magasins de données\n",
        "\n",
        "Dans Azure ML, les *magasins de données* sont des références à des emplacements de stockage, tels que des conteneurs d’objets blob de Stockage Azure. Chaque espace de travail possède un magasin de données par défaut, généralement le conteneur d’objets blob de Stockage Azure qui a été créé avec l’espace de travail. Si vous avez besoin d’utiliser des données stockées dans des emplacements différents, vous pouvez ajouter des magasins de données personnalisés à votre espace de travail, et définir l’un d’eux comme magasin par défaut.\n",
        "\n",
        "### Afficher les magasins de données\n",
        "\n",
        "Exécutez le code suivant pour déterminer les magasins de données dans votre espace de travail :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366185140
        }
      },
      "outputs": [],
      "source": [
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "# Enumerate all datastores, indicating which is the default\n",
        "for ds_name in ws.datastores:\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez également afficher et gérer des magasins de données dans votre espace de travail via la page **Magasins de données** de votre espace de travail dans [Azure Machine Learning studio](https://ml.azure.com).\n",
        "\n",
        "### Charger des données dans un magasin de données\n",
        "\n",
        "Maintenant que vous avez déterminé les magasins de données disponibles, vous pouvez charger des fichiers à partir de votre système de fichiers local vers un magasin de données accessible aux essais en cours d’exécution dans l’espace de travail, quel que soit l’endroit où s’exécute le script d’essai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366190608
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utiliser des jeux de données\n",
        "\n",
        "Azure Machine Learning fournit une abstraction pour les données sous la forme de *jeux de données*. Un jeu de données est une référence dont la version est gérée à un ensemble spécifique de données que vous pouvez utiliser dans un essai. Des jeux de données peuvent être *tabulaires* ou basés sur *fichier*.\n",
        "\n",
        "### Créer un jeu de données tabulaire\n",
        "\n",
        "Nous allons créer un jeu de données à partir des données sur le diabète que vous avez chargées dans le magasin de données, et afficher les 20 premiers enregistrements. En l’occurrence, les données étant dans un fichier de format structuré CSV, nous allons donc utiliser un jeu de données *tabulaire*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366193530
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "# Get the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Display the first 20 rows as a Pandas dataframe\n",
        "tab_data_set.take(20).to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme vous pouvez le voir dans le code ci-dessus, il est facile de convertir un jeu de données tabulaire en tramedonnées Pandas de façon à pouvoir utiliser les données à l’aide de techniques Python courantes.\n",
        "\n",
        "### Créer un jeu de données basé sur fichier\n",
        "\n",
        "Le jeu de données que vous avez créé est un jeu de données *tabulaire* qui peut être lu en tant que tramedonnées contenant toutes les données des fichiers structurés inclus dans la définition du jeu de données. Cela fonctionne bien pour les données tabulaires mais, dans certains scénarios d’apprentissage automatique, il se peut que vous deviez des données non structurées. Vous pouvez aussi simplement gérer la lecture des données à partir de fichiers dans votre propre code. Pour ce faire, vous pouvez utiliser un jeu de données basé sur *fichier*, qui crée une liste de chemins d’accès de fichiers dans un point de montage virtuel, que vous pouvez utiliser pour lire les données dans les fichiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366196795
        }
      },
      "outputs": [],
      "source": [
        "#Create a file dataset from the path on the datastore (this may take a short while)\n",
        "file_data_set = Dataset.File.from_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Get the files in the dataset\n",
        "for file_path in file_data_set.to_path():\n",
        "    print(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inscrire des jeux de données\n",
        "\n",
        "Maintenant que vous avez créé des jeux de données faisant référence aux données sur le diabète, vous pouvez les inscrire afin de les rendre facilement accessibles à tout essai exécuté dans l’espace de travail.\n",
        "\n",
        "Nous allons inscrire le jeu de données tabulaire en tant que **jeu de données diabète**, et le jeu de données basé sur fichier en tant que **fichiers diabète**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366200005
        }
      },
      "outputs": [],
      "source": [
        "# Register the tabular dataset\n",
        "try:\n",
        "    tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                        name='diabetes dataset',\n",
        "                                        description='diabetes data',\n",
        "                                        tags = {'format':'CSV'},\n",
        "                                        create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Register the file dataset\n",
        "try:\n",
        "    file_data_set = file_data_set.register(workspace=ws,\n",
        "                                            name='diabetes file dataset',\n",
        "                                            description='diabetes files',\n",
        "                                            tags = {'format':'CSV'},\n",
        "                                            create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "print('Datasets registered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez afficher et gérer des jeux de données via la page **jeux de données** de votre espace de travail dans [Azure Machine Learning studio](https://ml.azure.com). Vous pouvez également obtenir une liste de jeux de données à partir de l’objet espace de travail :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366204696
        }
      },
      "outputs": [],
      "source": [
        "print(\"Datasets:\")\n",
        "for dataset_name in list(ws.datasets.keys()):\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La capacité de gérer les versions des jeux de données vous permet de redéfinir des jeux de données sans interrompre des essais ou pipelines existants qui dépendent de définitions précédentes. Par défaut, la dernière version d’un jeu de données nommé est retournée, mais vous pouvez récupérer une version spécifique d’un jeu de données en spécifiant le numéro de version, comme suit :\n",
        "\n",
        "```python\n",
        "dataset_v1 = Dataset.get_by_name(ws, ’diabetes dataset’, version = 1)\n",
        "```\n",
        "\n",
        "\n",
        "### Effectuer l’apprentissage d’un modèle à partir d’un jeu de données tabulaire\n",
        "\n",
        "Maintenant que vous avez des jeux de données, vous êtes prêt à commencer à effectuer l’apprentissage de modèles à partir de ceux-ci. Vous pouvez transmettre des jeux de données à des scripts en tant qu’*entrées* dans l’estimateur utilisé pour exécuter le script.\n",
        "\n",
        "Exécutez les deux cellules de code suivantes pour créer :\n",
        "\n",
        "1. Un dossier nommé **diabetes_training_from_tab_dataset**\n",
        "2. Un script qui effectue l’apprentissage d’un modèle de classification à l’aide d’un jeu de données tabulaire qui lui est transmis en tant qu’argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366207914
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_tab_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Run, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Get the script arguments (regularization rate and training dataset ID)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Get the training dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Remarque** : dans le script, le jeu de données est transmis en tant que paramètre (ou argument). Dans le cas d’un jeu de données tabulaire, cet argument contiendra l’ID du jeu de données inscrit. Vous pourriez donc écrire du code dans le script pour récupérer l’espace de travail de l’essai à partir du contexte d’exécution, puis récupérer le jeu de données à l’aide de son ID, comme suit :\n",
        ">\n",
        "> ```\n",
        "> run = Run.get_context()\n",
        "> ws = run.experiment.workspace\n",
        "> dataset = Dataset.get_by_id(ws, id=args.training_dataset_id)\n",
        "> diabetes = dataset.to_pandas_dataframe()\n",
        "> ```\n",
        ">\n",
        "> Toutefois, Azure Machine Learning exécute automatiquement des arguments identify qui font référence à des jeux de données nommés, et les ajoutent à la collection **input_datasets** de l’exécution, de façon à ce que vous puissiez également récupérer le jeu de données à partir de cette collection en spécifiant son « nom convivial » (qui, comme vous le verrez bientôt, est spécifié dans la définition de l’argument dans la configuration de l’exécution du script pour l’essai). Il s’agit de l’approche adoptée dans le script ci-dessus.\n",
        "\n",
        "Vous pouvez maintenant exécuter un script en tant qu’essai, en définissant un argument pour le jeu de données d’apprentissage qui est lu par le script.\n",
        "\n",
        "> **Remarque** : la classe **Jeu de données** dépendant de certains composants du package **azureml-dataprep**, vous devez inclure ce package dans l’environnement où l’essai d’apprentissage sera exécutée. Le package **azureml-dataprep** est inclus dans le package **azure-defaults**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366222016
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "env = Environment.from_conda_specification(\"experiment_env\", \"environment.yml\")\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                              script='diabetes_training.py',\n",
        "                              arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                           '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                              environment=env,\n",
        "                              docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Remarque :** l’argument **--input-data** transmet le jeu de données en tant qu’*entrée nommée* incluant un *nom convivial* pour le jeu de données que le script utilise pour le lire à partir de la collection **input_datasets** lors de l’exécution de l’essai. La valeur de chaîne dans l’argument **--input-data** est en fait l’ID du jeu de données inscrit.  Une autre approche consiste à simplement transmettre « diabetes_ds.id », auquel cas le script peut accéder à l’ID du jeu de données à partir des arguments script, et l’utiliser pour récupérer le jeu de données à partir de l’espace de travail, mais pas à partir de la collection **input_datasets**.\n",
        "\n",
        "La première fois que l’essai est exécuté, la configuration de l’environnement Python peut prendre un certain temps. Les exécutions suivantes seront plus rapides.\n",
        "\n",
        "Une fois l’essai terminé, dans le widget, affichez le journal de sortie **azureml-logs/70_driver_log.txt** et les métriques générées par l’exécution.\n",
        "\n",
        "### Inscrire le modèle formé\n",
        "\n",
        "Comme pour toute essai d’apprentissage, vous pouvez récupérer le modèle formé et l’inscrire dans votre espace de travail Azure Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366229781
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Tabular dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Effectuer l’apprentissage d’un modèle à partir d’un jeu de données basé sur fichier\n",
        "\n",
        "Vous avez vu comment effectuer l’apprentissage d’un modèle à l’aide de données d’apprentissage dans un jeu de données *tabulaire*. Mais qu’en est-il d’un jeu de données basé sur *fichier* ?\n",
        "\n",
        "Lorsque vous utilisez un jeu de données basé sur fichier, l’argument dataset transmis au script représente un point de montage contenant des chemins d’accès de fichiers. La façon dont vous lisez les données de ces fichiers dépend du type de données et de ce que vous souhaitez en faire. Dans le cas des fichiers CSV diabetes, vous pouvez utiliser le module Python **glob** pour créer une liste de fichiers dans le point de montage virtuel défini par le jeu de données, et les lire tous dans des tramesdonnées Pandas qui sont concaténées dans une seule tramedonnées.\n",
        "\n",
        "Exécutez les deux cellules de code suivantes pour créer :\n",
        "\n",
        "1. Un dossier nommé **diabetes_training_from_file_dataset**\n",
        "2. Un script qui effectue l’apprentissage d’un modèle de classification à l’aide d’un jeu de données basé sur fichier qui lui est transmis en tant qu’*entrée*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366232676
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_from_file_dataset'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "from azureml.core import Dataset, Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import glob\n",
        "\n",
        "# Get script arguments (rgularization rate and file dataset mount point)\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument('--input-data', type=str, dest='dataset_folder', help='data mount point')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter (passed as an argument to the script)\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "data_path = run.input_datasets['training_files'] # Get the training data path from the input\n",
        "# (You could also just use args.dataset_folder if you don't want to rely on a hard-coded friendly name)\n",
        "\n",
        "# Read the files\n",
        "all_files = glob.glob(data_path + \"/*.csv\")\n",
        "diabetes = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tout comme un jeu de données tabulaire, vous pouvez récupérer un jeu de données basé sur fichier à partir de la collection **input_datasets** en utilisant son nom convivial. Vous pouvez également le récupérer à partir de l’argument script qui, dans le cas d’un jeu de données basé sur fichier, contient un chemin d’accès de montage aux fichiers (plutôt que l’ID de jeu de données transmis pour un jeu de données tabulaire).\n",
        "\n",
        "Ensuite, nous devons changer la façon dont nous transmettons le jeu de données au script en définissant un chemin d’accès à partir duquel le script peut lire les fichiers. Pour ce faire, vous pouvez utiliser la méthode **as_download** ou **as_mount**. L’utilisation de la méthode **as_download** a pour effet de télécharger le jeu de données basé sur fichier vers un emplacement temporaire sur l’instance de calcul où le script est en cours d’exécution, tandis que l’utilisation de la méthode **as_mount** a pour effet de créer un point de montage à partir duquel les fichiers peuvent être diffusés en continu directement à partir du magasin de données.\n",
        "\n",
        "Vous pouvez combiner la méthode d’accès à la méthode **as_named_input** pour inclure le jeu de données dans la collection **input_datasets** dans l’exécution de l’essai (si vous omettez cela, par exemple, en définissant l’argument sur « diabetes_ds.as_mount() », le script pourra accéder au point de montage du jeu de données à partir des arguments script, mais pas à partir de la collection **input_datasets**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366252096
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes file dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                             '--input-data', diabetes_ds.as_named_input('training_files').as_download()], # Reference to dataset location\n",
        "                                environment=env, # Use the environment created previously\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True))\n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une fois l’essai terminé, dans le widget, consultez le journal de sortie **azureml-logs/70_driver_log.txt** pour vérifier que les fichiers du jeu de données basé sur fichier ont été téléchargés dans un dossier temporaire pour permettre au script de les lire.\n",
        "\n",
        "### Inscrire le modèle formé\n",
        "\n",
        "Une fois encore, vous pouvez inscrire le modèle dont l’apprentissage a été effectué par l’essai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366260993
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'File dataset'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Informations supplémentaires** : pour plus d’informations sur l’apprentissage avec des jeux de données, consultez [Apprentissage avec des jeux de données](https://docs.microsoft.com/azure/machine-learning/how-to-train-with-datasets) dans la documentation Azure ML."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
