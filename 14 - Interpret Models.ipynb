{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpréter les modèles\n",
    "\n",
    "Vous pouvez utiliser Azure Machine Learning pour interpréter un modèle à l’aide d’un *explicateur* qui quantifie l’influence de chaque caractéristique sur l’étiquette prédite. Il existe de nombreux explicateurs courants, adaptés aux différents types d’algorithmes de modélisation, mais l’approche de base de leur utilisation est la même.\n",
    "\n",
    "## Installer des packages de Kit de développement logiciel (SDK)\n",
    "\n",
    "En plus de la dernière version des packages **azureml-SDK** et **azureml-widgets**, vous aurez besoin du package **azureml-explain-model** pour exécuter le code contenu dans ce notebook. Vous allez également utiliser la bibliothèque d’interprétabilité d’Azure ML (**azureml-interpret**). Vous pouvez l’utiliser pour interpréter de nombreux genres typiques de modèles, même si leur apprentissage n’a pas été effectué dans une expérience Azure ML ou s’ils n’ont pas été inscrits dans un espace de travail Azure ML.\n",
    "\n",
    "Exécutez la cellule ci-dessous pour vérifier que ces packages sont installés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1649368363682
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pip show azureml-explain-model azureml-interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expliquer un modèle\n",
    "\n",
    "Commençons par un modèle dont l’apprentissage a été effectué en dehors d’Azure Machine Learning. Exécutez la cellule ci-dessous pour effectuer l’apprentissage d’un modèle de classification d’arbre de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "labels = ['not-diabetic', 'diabetic']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "\n",
    "print('Model trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le processus d’apprentissage a généré des métriques d’évaluation du modèle sur la base d’un jeu de données de validation de conservation. Vous avez donc une idée de la précision des prédictions, mais comment les caractéristiques des données influencent-elles la prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir un explicateur pour le modèle\n",
    "\n",
    "Nous allons obtenir un explicateur approprié pour le modèle à partir de la bibliothèque d’interprétabilité d’Azure ML que vous avez installée précédemment. Il existe de nombreux types d’explicateurs. Dans cet exemple, vous allez utiliser un *Explicateur tabulaire*, qui est un explicateur « boîte noire » utilisable pour expliquer de nombreux genres de modèles en appelant un explicateur de modèle [SHAP](https://github.com/slundberg/shap) approprié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "# \"features\" and \"classes\" fields are optional\n",
    "tab_explainer = TabularExplainer(model,\n",
    "                             X_train, \n",
    "                             features=features, \n",
    "                             classes=labels)\n",
    "print(tab_explainer, \"ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir l’importance d’une caractéristique *globale*\n",
    "\n",
    "La première chose à faire est d’essayer d’expliquer le modèle en évaluant l’*importance d’une caractéristique* globale, autrement dit, en quantifiant l’influence de chaque caractéristique sur la prédiction en fonction de l’ensemble du jeu de données d’apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# you can use the training data or the test data here\n",
    "global_tab_explanation = tab_explainer.explain_global(X_train)\n",
    "\n",
    "# Get the top features by importance\n",
    "global_tab_feature_importance = global_tab_explanation.get_feature_importance_dict()\n",
    "for feature, importance in global_tab_feature_importance.items():\n",
    "    print(feature,\":\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’importance d’une caractéristique est classée, la caractéristique la plus importante venant en premier.\n",
    "\n",
    "### Obtenir l’importance d’une caractéristique *locale*\n",
    "\n",
    "Vous disposez donc d’une vue globale, mais qu’en est-il de l’explication d’observations individuelles ? Générons des explications *locales* pour des prédictions individuelles, en quantifiant l’influence de chaque caractéristique sur la décision de prédire chacune des valeurs d’étiquette possibles. Dans ce cas, comme il s’agit d’un modèle binaire, il y a deux étiquettes possibles (non diabétique et diabétique). Vous pouvez quantifier l’influence de chaque caractéristique pour chacune de ces valeurs d’étiquette pour des observations individuelles dans un jeu de données. Vous allez juste évaluer les deux premiers cas dans le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Get the observations we want to explain (the first two)\n",
    "X_explain = X_test[0:2]\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_explain)\n",
    "\n",
    "# Get local explanations\n",
    "local_tab_explanation = tab_explainer.explain_local(X_explain)\n",
    "\n",
    "# Get feature names and importance for each possible label\n",
    "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
    "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
    "\n",
    "for l in range(len(local_tab_features)):\n",
    "    print('Support for', labels[l])\n",
    "    label = local_tab_features[l]\n",
    "    for o in range(len(label)):\n",
    "        print(\"\\tObservation\", o + 1)\n",
    "        feature_list = label[o]\n",
    "        total_support = 0\n",
    "        for f in range(len(feature_list)):\n",
    "            print(\"\\t\\t\", feature_list[f], ':', local_tab_importance[l][o][f])\n",
    "            total_support += local_tab_importance[l][o][f]\n",
    "        print(\"\\t\\t ----------\\n\\t\\t Total:\", total_support, \"Prediction:\", labels[predictions[o]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout d’explicabilité à une expérience d’apprentissage de modèle\n",
    "\n",
    "Comme vous l’avez vu, vous pouvez générer des explications pour des modèles dont l’apprentissage a été effectué en dehors d’Azure Machine Learning. Toutefois, lorsque vous utilisez des expériences pour effectuer l’apprentissage de modèles et les inscrire dans votre espace de travail Azure Machine Learning, vous pouvez générer des explications de modèle et les journaliser.\n",
    "\n",
    "Exécutez le code dans la cellule suivante pour vous connecter à votre espace de travail.\n",
    "\n",
    "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectuer l’apprentissage d’un modèle et l’expliquer à l’aide d’une expérience\n",
    "\n",
    "OK. Créons une expérience et plaçons les fichiers dont elle a besoin dans un dossier local. Dans ce cas, nous allons simplement utiliser le même fichier CSV de données sur le diabète pour effectuer l’apprentissage du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_train_and_explain'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/diabetes.csv', os.path.join(experiment_folder, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À présent, nous allons créer un script d’apprentissage ressemblant à tout autre script d’apprentissage Azure ML, sauf qu’il inclut les caractéristiques suivantes :\n",
    "\n",
    "- Les bibliothèques pour générer des explications de modèle que nous avons utilisées avant sont importées et utilisées pour générer une explication globale.\n",
    "- La bibliothèque **ExplanationClient** est utilisée pour charger l’explication de la sortie de l’expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Import Azure ML run library\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Import libraries for model explanation\n",
    "from azureml.interpret import ExplanationClient\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "labels = ['not-diabetic', 'diabetic']\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes.pkl')\n",
    "\n",
    "# Get explanation\n",
    "explainer = TabularExplainer(model, X_train, features=features, classes=labels)\n",
    "explanation = explainer.explain_global(X_test)\n",
    "\n",
    "# Get an Explanation Client and upload the explanation\n",
    "explain_client = ExplanationClient.from_run(run)\n",
    "explain_client.upload_model_explanation(explanation, comment='Tabular Explanation')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’expérience nécessitant un environnement Python dans lequel exécuter le script, nous allons donc définir une spécification Conda pour celui-ci. Notez que la bibliothèque **azureml-interpret** étant incluse dans l’environnement d’apprentissage, le script peut créer un **TabularExplainer** et utiliser la classe **ExplainerClient**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/interpret_env.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - azureml-interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant exécuter l’expérience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "explain_env = Environment.from_conda_specification(\"explain_env\", experiment_folder + \"/interpret_env.yml\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                      script='diabetes_training.py',\n",
    "                      environment=explain_env,\n",
    "                      docker_runtime_config=DockerConfiguration(use_docker=True)) \n",
    "\n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-diabetes-explain'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupérer les valeurs d’importance d’une caractéristique\n",
    "\n",
    "Une fois l’expérience terminée, vous pouvez utiliser la classe **ExplanationClient** pour récupérer l’importance d’une caractéristique à partir de l’explication inscrite pour l’exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "# Get the feature explanations\n",
    "client = ExplanationClient.from_run(run)\n",
    "engineered_explanations = client.download_model_explanation()\n",
    "feature_importances = engineered_explanations.get_feature_importance_dict()\n",
    "\n",
    "# Overall feature importance\n",
    "print('Feature\\tImportance')\n",
    "for key, value in feature_importances.items():\n",
    "    print(key, '\\t', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher l’explication du modèle dans Azure Machine Learning studio\n",
    "\n",
    "Vous pouvez également cliquer sur le lien **Afficher les détails de l’exécution** dans le widget Détails de l’exécution pour voir l’exécution dans Azure Machine Learning studio et afficher l’onglet **Explications**. Ensuite :\n",
    "\n",
    "1. Sélectionnez l’ID d’explication de votre explicateur tabulaire.\n",
    "2. Affichez le graphique **Importance d’une caractéristique agrégée**, qui affiche l’importance d’une caractéristique globale.\n",
    "3. Affichez le graphique **Importance d’une caractéristique individuelle**, qui affiche chaque point de données à partir des données de test.\n",
    "4. Sélectionnez un point individuel pour afficher l’importance d’une caractéristique locale pour la prédiction individuelle pour le point de données sélectionné.\n",
    "5. Utilisez le bouton **Nouvelle cohorte** pour définir un sous-ensemble des données avec les paramètres suivants :\n",
    "    - **Nom de la cohorte du jeu de données** : sous 25.\n",
    "    - **Sélectionner un filtre** : Jeu de données\n",
    "        - Âge inférieur à 25 (veillez à ajouter ce filtre avant d’enregistrer la nouvelle cohorte).\n",
    "6. Créez une deuxième nouvelle cohorte nommée **25 et plus** avec un filtre sur Âge supérieur ou égal à 25.\n",
    "6. Examinez la visualisation **Importance d’une caractéristique agrégée** et comparez l’importance d’une caractéristique relative pour les deux cohortes que vous avez définies. La possibilité de comparer des cohortes permet de voir comment les caractéristiques influencent les prédictions différemment pour plusieurs sous-ensembles de la population de données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informations supplémentaires** : pour plus d’informations sur l’utilisation d’explicateurs dans Azure ML, consultez la [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-machine-learning-interpretability). "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
