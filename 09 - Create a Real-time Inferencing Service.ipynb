{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Créer un service d’inférence en temps réel\n",
        "\n",
        "Après avoir effectué l’apprentissage d’un modèle prédictif, vous pouvez le déployer en tant que service en temps réel que les clients peuvent utiliser pour obtenir des prédictions à partir de nouvelles données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vous connecter à votre espace de travail\n",
        "\n",
        "Pour commencer, connectez-vous à votre espace de travail.\n",
        "\n",
        "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367571437
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Effectuer l’apprentissage un modèle et l’inscrire\n",
        "\n",
        "Nous allons maintenant effectuer l’apprentissage d’un modèle et l’inscrire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367606601
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name=\"mslearn-train-diabetes\")\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "print('Model trained and registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Déploiement du modèle en tant que service web\n",
        "\n",
        "Vous avez effectué l’apprentissage d’un modèle d’apprentissage automatique qui classifie les patients en fonction de la probabilité qu’ils soient atteints de diabète, et l’avez inscrit. Ce modèle pourrait être utilisé dans un environnement de production, tel qu’un cabinet médical où seuls les patients jugés à risque doivent être soumis à un test clinique pour le diabète. Pour prendre en charge ce scénario, vous allez déployer le modèle en tant que service web.\n",
        "\n",
        "Tout d’abord, nous allons déterminer les modèles que vous avez inscrits dans l’espace de travail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bien, prenons le modèle que nous voulons déployer. Par défaut, si nous spécifions un nom de modèle, la version la plus récente sera retournée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ws.models['diabetes_model']\n",
        "print(model.name, 'version', model.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons créer un service web pour héberger ce modèle, ce qui nécessitera du code et des fichiers de configuration. Créons donc un dossier pour ceux-ci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the deployment files\n",
        "deployment_folder = './diabetes_service'\n",
        "os.makedirs(deployment_folder, exist_ok=True)\n",
        "print(deployment_folder, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = 'score_diabetes.py'\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le service web dans lequel nous déployons le modèle aura besoin de code Python pour charger les données d’entrée, obtenir le modèle à partir de l’espace de travail, puis générer et retourner des prédictions. Nous allons enregistrer ce code dans un *script d’entrée* (souvent appelé *script de scoring*) qui sera déployé sur le service web.\n",
        "\n",
        "Le script se compose de deux fonctions :\n",
        "\n",
        "- **init** : cette fonction est appelée lors de l’initialisation du service, et est généralement utilisée pour charger le modèle. Notez que le script de scoring utilise la variable d’environnement **AZUREML_MODEL_DIR** pour déterminer le dossier dans lequel le modèle est stocké.\n",
        "- **run** : cette fonction est appelée chaque fois qu’une application cliente envoie de nouvelles données, et généralement utilisée pour inférer des prédictions à partir du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $script_path\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = np.array(json.loads(raw_data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(data)\n",
        "    # Get the corresponding classname for each prediction (0 or 1)\n",
        "    classnames = ['not-diabetic', 'diabetic']\n",
        "    predicted_classes = []\n",
        "    for prediction in predictions:\n",
        "        predicted_classes.append(classnames[prediction])\n",
        "    # Return the predictions as JSON\n",
        "    return json.dumps(predicted_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le service web sera hébergé dans un conteneur, et le conteneur devra installer toutes les dépendances Python requises lors de son initialisation. Dans ce cas, notre code de scoring requiert **scikit-learn** et certains packages Azure Machine Learning spécifiques que le service web de scoring utilise. Nous allons donc créer un environnement qui les inclut. Nous allons ensuite ajouter cet environnement à une *configuration d’inférence* avec le script de scoring, puis définir une *configuration de déploiement* pour le conteneur dans lequel l’environnement et le script seront hébergés.\n",
        "\n",
        "Nous pourrons alors déployer le modèle en tant que service sur la base de ces configurations.\n",
        "\n",
        "> ** Informations supplémentaires** : pour plus de détails sur le déploiement du modèle et les options pour les environnements d’exécution cibles, consultez la [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where).\n",
        "\n",
        "Le déploiement prendra un certain temps, car il exécute un processus pour créer une image conteneur, avant d’exécuter un processus pour créer un service web basé sur l’image. Une fois le déploiement terminé, vous verrez un état **Sain**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Configure the scoring environment\n",
        "service_env = Environment(name='service-env')\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
        "for package in python_packages:\n",
        "    service_env.python.conda_dependencies.add_pip_package(package)\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
        "                                   entry_script=script_file,\n",
        "                                   environment=service_env)\n",
        "\n",
        "# Configure the web service container\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "# Deploy the model as a service\n",
        "print('Deploying model...')\n",
        "service_name = \"diabetes-service\"\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En principe, le déploiement a réussi et vous pouvez voir un état **Sain**. Si ce n’est pas le cas, vous pouvez utiliser le code suivant afin d’obtenir les journaux d’activité de service pour vous aider à résoudre les problèmes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(service.get_logs())\n",
        "\n",
        "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
        "#service.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jetez un coup d’œil à votre espace de travail dans [Azure Machine Learning Studio](https://ml.azure.com) et consultez la page **Points de terminaison**, qui affiche les services déployés dans votre espace de travail.\n",
        "\n",
        "Vous pouvez également récupérer les noms des services web dans votre espace de travail en exécutant le code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for webservice_name in ws.webservices:\n",
        "    print(webservice_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utiliser le service web\n",
        "\n",
        "Une fois le service déployé, vous pouvez l’utiliser à partir d’une application cliente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
        "print ('Patient: {}'.format(x_new[0]))\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
        "predictions = service.run(input_data = input_json)\n",
        "\n",
        "# Get the predicted class - it'll be the first (and only) one.\n",
        "predicted_classes = json.loads(predictions)\n",
        "print(predicted_classes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez également envoyer plusieurs observations de patients au service et récupérer une prédiction pour chacune d’elles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# This time our input is an array of two feature arrays\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array or arrays to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Call the web service, passing the input data\n",
        "predictions = service.run(input_data = input_json)\n",
        "\n",
        "# Get the predicted classes.\n",
        "predicted_classes = json.loads(predictions)\n",
        "   \n",
        "for i in range(len(x_new)):\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le code ci-dessus utilise le Kit de développement logiciel (SDK) Azure Machine Learning pour se connecter au service web conteneurisé, et l’utiliser pour générer des prédictions à partir de votre modèle de classification du diabète. En production, un modèle est susceptible d’être consommé par des applications métier qui n’utilisent pas le Kit de développement logiciel (SDK) Azure Machine Learning, mais adressent simplement des requêtes HTTP au service web.\n",
        "\n",
        "Nous allons déterminer l’URL à laquelle ces applications doivent envoyer leurs requêtes :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint = service.scoring_uri\n",
        "print(endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maintenant que vous connaissez l’URI du point de terminaison, une application peut simplement effectuer une requête HTTP en envoyant les données patient au format JSON, et recevoir en retour la ou les classes prédites."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\n",
        "predicted_classes = json.loads(predictions.json())\n",
        "\n",
        "for i in range(len(x_new)):\n",
        "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous avez déployé votre service web en tant que service Azure Container Instance (ACI) ne nécessitant aucune authentification. Cela est parfait pour le développement et les tests mais, pour la production, vous devriez envisager un déploiement sur un cluster Azure Kubernetes Service (AKS) et l’activation de l’authentification basée sur un jeton. Cela nécessiterait que les requêtes REST incluent un en-tête **Authorization**.\n",
        "\n",
        "## Supprimer le service\n",
        "\n",
        "Lorsque vous n’avez plus besoin de votre service, vous devriez le supprimer pour éviter des frais inutiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()\n",
        "print ('Service deleted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour plus d’informations sur la publication d’un modèle en tant que service, consultez la [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
