{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utiliser une instance de calcul\n",
        "\n",
        "Quand vous exécutez un script en tant qu’essai Azure Machine Learning, vous devez définir son contexte d’exécution. Le contexte d’exécution est constitué des éléments suivants :\n",
        "\n",
        "* Environnement Python pour le script, qui doit inclure tous les packages Python utilisés dans celui-ci.\n",
        "* Cible de calcul sur laquelle le script sera exécuté. Il pourrait s’agir de la station de travail locale à partir de laquelle l’exécution de l’essai est lancée, ou d’une cible de calcul distante comme un cluster d’apprentissage configuré à la demande.\n",
        "\n",
        "Dans ce notebook, vous allez explorer des *environnements* et *cibles de calcul* pour les essais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vous connecter à votre espace de travail\n",
        "\n",
        "Pour commencer, connectez-vous à votre espace de travail.\n",
        "\n",
        "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366407895
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Préparer les données pour un essai\n",
        "\n",
        "Dans ce notebook, vous allez utiliser un jeu de données contenant des détails sur des patients atteints d’un diabète. Exécutez la cellule ci-dessous pour créer ce jeu de données (s’il existe déjà, le code trouvera la version existante)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366412436
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer un script d’apprentissage\n",
        "\n",
        "Exécutez les deux cellules suivantes afin de créer :\n",
        "\n",
        "1. Un dossier pour un nouvel essai.\n",
        "2. Un fichier de script d’apprentissage utilisant **scikit-learn** pour effectuer l’apprentissage d’un modèle, et **matplotlib** pour tracer une courbe ROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366415622
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_logistic'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import argparse\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Set regularization hyperparameter\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "run.log('Regularization Rate',  np.float(reg))\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Définir un environnement\n",
        "\n",
        "Quand vous exécutez un script Python en tant qu’essai dans Azure Machine Learning, un environnement Conda est créé pour définir le contexte d’exécution du script. Azure Machine Learning fournit un environnement par défaut qui inclut de nombreux packages courants, dont le package **azureml-defaults** qui contient les bibliothèques nécessaires pour exécuter un essai, ainsi que des packages populaires comme **pandas** et **numpy**.\n",
        "\n",
        "Vous pouvez également définir votre propre environnement dans un fichier de spécification Conda, en ajoutant des packages à l’aide de **Conda** ou **PIP** pour vous assurer que votre essai ait accès à toutes les bibliothèques requises.\n",
        "\n",
        "> **Remarque** : les dépendances conda sont installées en premier, suivies des dépendances pip. Étant donné que le package **pip** est requis pour installer les dépendances pip, il est recommandé de l’inclure dans les dépendances conda.\n",
        "\n",
        "Exécutez la cellule suivante pour créer un fichier de spécification Conda nommé *experiment_env. yml* dans le même dossier que ce notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "  # The python interpreter version.\n",
        "  # Currently Azure ML only supports 3.5.2 and later.\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez maintenant utiliser votre fichier de spécification conda personnalisé pour créer un environnement pour votre essai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366425019
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Let Azure ML manage dependencies\n",
        "experiment_env.python.user_managed_dependencies = False \n",
        "\n",
        "# Print the environment details\n",
        "print(experiment_env.name, 'defined.')\n",
        "print(experiment_env.python.conda_dependencies.serialize_to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez maintenant utiliser l’environnement pour exécuter un script en tant qu’essai.\n",
        "\n",
        "Le code suivant affecte l’environnement que vous avez créé à un ScriptRunConfig, et soumet un essai. Pendant l’exécution de l’essai, vous pouvez observer les détails de l’exécution dans le widget et dans le journal de sortie **azureml_logs/60_control_log. txt**, pour voir l’environnement Conda en cours de génération.\n",
        "\n",
        "> **Remarque** : le code ci-dessous crée une **DockerConfiguration** pour l’exécution du script, et définit son attribut **use_docker** sur **True** pour héberger l’environnement du script dans un conteneur Docker. Comme il s’agit du comportement par défaut, vous pouvez l’omettre. Nous l’incluons ici pour être explicite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366440060
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
        "                                             '--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                                environment=experiment_env,\n",
        "                                docker_runtime_config=DockerConfiguration(use_docker=True)) # Use docker to host environment\n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L’essai a utilisé avec succès l’environnement qui incluait tous les packages requis. Vous pouvez afficher les métriques et sorties de l’exécution de l’essai dans Azure Machine Learning studio, ou en exécutant le code ci-dessous, incluant le modèle formé à l’aide de **scikit-learn** et l’image de graphique ROC générée à l’aide de **matplotlib**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366443126
        }
      },
      "outputs": [],
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inscrire l’environnement\n",
        "\n",
        "Après avoir pris la peine de définir un environnement avec les packages dont vous avez besoin, vous pouvez l’inscrire dans l’espace de travail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366446255
        }
      },
      "outputs": [],
      "source": [
        "# Register the environment\n",
        "experiment_env.register(workspace=ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notez que l’environnement est inscrit sous le nom que vous lui avez donné lorsque vous l’avez créé pour la première fois (dans ce cas, *diabetes-experiment-env*).\n",
        "\n",
        "Une fois l’environnement inscrit, vous pouvez le réutiliser pour tous les scripts qui ont les mêmes exigences. Par exemple, nous allons créer un dossier et un script pour effectuer l’apprentissage d’un modèle diabète à l’aide d’un algorithme différent :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366449250
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the experiment files\n",
        "experiment_folder = 'diabetes_training_tree'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "print(experiment_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/diabetes_training.py\n",
        "# Import libraries\n",
        "import argparse\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get script arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the diabetes data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
        "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez maintenant récupérer l’environnement inscrit et l’utiliser dans un nouvel essai qui exécute le script d’apprentissage alternatif (cette fois, il n’y a aucun paramètre de régularisation, car aucun classifieur d’arbre de décision ne l’exige)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366472876
        }
      },
      "outputs": [],
      "source": [
        "# get the registered environment\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                              script='diabetes_training.py',\n",
        "                              arguments = ['--input-data', diabetes_ds.as_named_input('training_data')], # Reference to dataset\n",
        "                              environment=registered_env,\n",
        "                              docker_runtime_config=DockerConfiguration(use_docker=True)) # Use docker to host environment \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cette fois, l’essai s’exécute plus rapidement car, un environnement correspondant ayant été mis en cache à partir de l’exécution précédente, il n’est pas nécessaire de le recréer l’instance de calcul locale. Toutefois, même sur une cible de calcul différente, le même environnement serait créé et utilisé afin de garantir la cohérence du contexte d’exécution de votre script d’essai.\n",
        "\n",
        "Examinons les métriques et sorties de l’essai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366477009
        }
      },
      "outputs": [],
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Afficher les environnements inscrits\n",
        "\n",
        "Outre l’inscription de vos propres environnements, vous pouvez tirer parti d’environnements organisés « prédéfinis » pour des types d’essais courants. Le code suivant répertorie tous les environnements inscrits :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366479796
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "envs = Environment.list(workspace=ws)\n",
        "for env in envs:\n",
        "    print(\"Name\",env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tous les environnements organisés portent des noms commençant par ***AzureML-*** (vous ne pouvez pas utiliser ce préfixe pour vos propres environnements)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer un cluster de calcul\n",
        "\n",
        "Dans de nombreux cas, il se peut que vos ressources de calcul locales ne soient pas suffisantes pour traiter un essai complexe ou de longue durée qui doit traiter un volume important de données, et vous pouvez tirer parti de la possibilité de créer et d’utiliser de façon dynamique des ressources de calcul dans le cloud. Azure Machine Learning prend en charge une plage de cibles de calcul, que vous pouvez définir dans votre espace de travail et utiliser pour exécuter des essais, en ne payant pour les ressources que si vous les utilisez.\n",
        "\n",
        "Vous pouvez créer un cluster de calcul dans [Azure Machine Learning studio](https://ml.azure.com), ou à l’aide du Kit de développement logiciel (SDK) Azure Machine Learning. La cellule de code suivante recherche dans votre espace de travail l’existence d’un cluster de calcul avec un nom spécifié et, s’il n’existe pas, le crée.\n",
        "\n",
        "> **Important** : remplacez *your-compute-cluster* par un nom approprié pour votre cluster de calcul dans le code ci-dessous avant de l’exécuter. Vous pouvez spécifier le nom d’un cluster existant si vous en avez un. Les noms de cluster doivent être globalement uniques, et d’une longueur comprise entre 2 et 16 caractères. Les caractères valides sont les lettres, les chiffres et le tiret (-)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366493624
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        training_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Remarque** : les clusters et instances de calcul sont basés sur des images de machines virtuelles Azure standard. Pour cet exercice, l’image *Standard_DS11_v2* est recommandée pour obtenir l’équilibre optimal entre coûts et performances. Si votre abonnement s’accompagne d’un quota qui ne couvre pas cette image, choisissez-en une autre. Gardez cependant à l’esprit qu’une image plus grande peut entraîner des coûts plus élevés, tandis qu’une plus petite risque de ne pas suffire pour effectuer les tâches. Vous pouvez également demander à votre administrateur Azure d’étendre votre quota.\n",
        "\n",
        "## Exécuter un essai sur une instance de calcul à distance\n",
        "\n",
        "Vous êtes maintenant prêt à réexécuter l’essai que vous avez exécuté précédemment, mais cette fois sur le cluster de calcul que vous avez créé. \n",
        "\n",
        "> **Remarque** : l’essai prendra beaucoup plus de temps, car une image conteneur doit être générée avec l’environnement conda, puis les nœuds de cluster doivent être démarrés et l’image déployée avant l’exécution du script. Pour un essai simple, comme le script d’apprentissage pour le diabète, cela peut paraître inefficace. Pour un essai plus complexe nécessitant plusieurs heures, la création dynamique d’une instance de calcul plus évolutive peut réduire sensiblement le temps global d’exécution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366501837
        }
      },
      "outputs": [],
      "source": [
        "# Create a script config\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
        "                                script='diabetes_training.py',\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
        "                                environment=registered_env,\n",
        "                                compute_target=cluster_name) \n",
        "\n",
        "# submit the experiment\n",
        "experiment_name = 'mslearn-train-diabetes'\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\n",
        "run = experiment.submit(config=script_config)\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pendant que vous attendez l’exécution de l’essai, vous pouvez vérifier l’état du calcul dans le widget ci-dessus ou dans [Azure Machine Learning studio](https://ml.azure.com). Vous pouvez également vérifier l’état du calcul à l’aide du code ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649366504636
        }
      },
      "outputs": [],
      "source": [
        "cluster_state = training_cluster.get_status()\n",
        "print(cluster_state.allocation_state, cluster_state.current_node_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notez qu’il faut un certain temps avant que l’état passe de *stable* à *redimensionnement* (c’est peut-être le moment de prendre une pause café). Pour bloquer le noyau jusqu’à ce que l’exécution se termine, exécutez la cellule ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367026789
        }
      },
      "outputs": [],
      "source": [
        "run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gardez un œil sur l’indicateur de noyau en haut à droite de la page. Quand il passe de **&#9899;** à **&#9711;**, l’exécution du code est terminée.\n",
        "\n",
        "Une fois l’essai terminé, vous pouvez récupérer les métriques et les fichiers générés par son exécution. Cette fois, les fichiers incluent des journaux pour la création de l’image et la gestion du calcul."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367036387
        }
      },
      "outputs": [],
      "source": [
        "# Get logged metrics\n",
        "metrics = run.get_metrics()\n",
        "for key in metrics.keys():\n",
        "        print(key, metrics.get(key))\n",
        "print('\\n')\n",
        "for file in run.get_file_names():\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez maintenant inscrire le modèle dont l’apprentissage a été effectué par l’essai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367039203
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register the model\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Compute cluster'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Informations supplémentaires** :\n",
        ">\n",
        "> - Pour plus d’informations sur les environnements dans Azure Machine Learning, consultez [Créer et utiliser des environnements logiciels dans Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments)\n",
        "> - Pour plus d’informations sur les cibles de calcul dans Azure Machine Learning, consultez [Que sont les cibles de calcul dans Azure Machine Learning ?](https://docs.microsoft.com/azure/machine-learning/concept-compute-target)."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
