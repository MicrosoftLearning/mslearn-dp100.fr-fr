{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Créer un pipeline\n",
        "\n",
        "Vous pouvez accomplir les différentes étapes requises pour ingérer des données, effectuer l’apprentissage d’un modèle et inscrire le modèle individuellement à l’aide du Kit de développement logiciel (SDK) Azure ML SDK afin d’exécuter des expérimentations basées sur des scripts. Toutefois, dans un environnement d’entreprise, il est courant d’encapsuler la séquence des étapes requises pour générer une solution d’apprentissage automatique dans un *pipeline* exécutable sur une ou plusieurs cibles de calcul, soit à la demande d’un utilisateur, soit en vertu d’un processus de génération automatisé ou d’une planification.\n",
        "\n",
        "Dans ce notebook, vous allez réunir tous ces éléments pour créer un pipeline simple qui prétraite les données, puis effectue l’apprentissage d’un modèle et inscrit celui-ci."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vous connecter à votre espace de travail\n",
        "\n",
        "Pour commencer, connectez-vous à votre espace de travail.\n",
        "\n",
        "> **Remarque** : si vous n’avez pas encore établi de session authentifiée avec votre abonnement Azure, vous serez invité à vous authentifier en cliquant sur un lien, en saisissant un code d’authentification et en vous connectant à Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367166880
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Préparer les données\n",
        "\n",
        "Dans votre pipeline, vous allez utiliser un jeu de données contenant des détails sur des patients atteints de diabète. Exécutez la cellule ci-dessous pour créer ce jeu de données (si vous l’avez créé précédemment, le code trouvera la version existante)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367169674
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    Dataset.File.upload_directory(src_dir='data',\n",
        "                              target=DataPath(default_ds, 'diabetes-data/')\n",
        "                              )\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer des scripts pour des étapes de pipeline\n",
        "\n",
        "Les pipelines se composent d’une ou plusieurs *étapes*, qui peuvent être des scripts Python, ou des étapes spécialisées comme une étape de transfert de données qui copie des données d’un emplacement vers un autre. Chaque étape peut s’exécuter dans son propre contexte de calcul. Dans cet exercice, vous allez créer un pipeline simple contenant deux étapes de script Python : l’une pour prétraiter certaines données d’apprentissage, et l’autre pour utiliser les données prétraitées afin d’effectuer l’apprentissage d’un modèle et d’inscrire celui-ci.\n",
        "\n",
        "Commençons par créer un dossier pour les fichiers de script que nous allons utiliser dans les étapes du pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367172572
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Create a folder for the pipeline step files\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Créons maintenant le premier script qui lira les données du jeu de données sur le diabète, puis appliquera un prétraitement simple pour supprimer toutes les lignes dans lesquelles des données sont manquantes et normaliser les fonctionnalités numériques afin que celles-ci soient à une échelle similaire.\n",
        "\n",
        "Le script inclut un argument nommé **--prepped-data**, qui fait référence au dossier dans lequel les données obtenues devraient être enregistrées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the data (passed as an input dataset)\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# remove nulls\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez maintenant créer le script pour la deuxième étape, ce qui aura pour effet d’effectuer l’apprentissage d’un modèle. Le script inclut un argument nommé **--training-data**, qui fait référence à l’emplacement où les données préparées ont été enregistrées à l’étape précédente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
        "args = parser.parse_args()\n",
        "training_data = args.training_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the prepared data file in the training folder\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_data,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train adecision tree model\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Préparer un environnement de calcul pour les étapes du pipeline\n",
        "\n",
        "Dans cet exercice, vous allez utiliser le même calcul pour les deux étapes, mais il est important de comprendre que chaque étape est exécutée indépendamment. Vous pourriez donc spécifier des contextes de calcul différents pour chaque étape si nécessaire.\n",
        "\n",
        "Commencez par récupérer la cible de calcul que vous avez créée dans un labo précédent (si elle n’existe pas, elle sera créée).\n",
        "\n",
        "> **Important** : remplacez *your-compute-cluster* par le nom de votre cluster de calcul dans le code ci-dessous avant de l’exécuter. Les noms de cluster doivent être des noms globalement uniques d’une longueur comprise entre 2 et 16 caractères. Les caractères valides sont les lettres, les chiffres et le caractère « - »."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367181165
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"your-compute-cluster\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Remarque** : les clusters et instances de calcul sont basés sur des images de machines virtuelles Azure standard. Pour cet exercice, l’image *Standard_DS11_v2* est recommandée pour obtenir l’équilibre optimal entre coûts et performances. Si votre abonnement s’accompagne d’un quota qui ne couvre pas cette image, choisissez-en une autre. Gardez cependant à l’esprit qu’une image plus grande peut entraîner des coûts plus élevés, tandis qu’une plus petite risque de ne pas suffire pour effectuer les tâches. Vous pouvez également demander à votre administrateur Azure d’étendre votre quota.\n",
        "\n",
        "Le calcul nécessitera un environnement Python avec les dépendances de package nécessaires installées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\n",
        "name: experiment_env\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- ipykernel\n",
        "- matplotlib\n",
        "- pandas\n",
        "- pip\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maintenant que vous disposez d’un fichier de configuration Conda, vous pouvez créer un environnement et l’utiliser dans la configuration d’exécution pour le pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367186836
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment (from a .yml file)\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
        "\n",
        "# Register the environment \n",
        "experiment_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'experiment_env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Créer et exécuter un pipeline\n",
        "\n",
        "Vous êtes maintenant prêt à créer et exécuter un pipeline.\n",
        "\n",
        "Vous devez commencer par définir les étapes du pipeline, ainsi que toutes les références de données qui doivent être transmises entre elles. Dans ce cas, la première étape doit écrire les données préparées dans un dossier qui peut être lu à partir de la deuxième étape. Étant donné que les étapes seront exécutées sur une instance de calcul distante (et pourraient être exécutées sur une instance de calcul différente), le chemin d’accès au dossier doit être transmis en tant que référence de données à un emplacement dans un magasin de données au sein de l’espace de travail. L’objet **OutputFileDatasetConfig** est un type spécial de référence de données utilisé pour des emplacements de stockage intermédiaires qui peuvent être transmis entre étapes du pipeline. Vous allez donc en créer un et l’utiliser comme sortie pour la première étape et entrée pour la deuxième. Notez que vous devez le passer en tant qu’argument de script afin que votre code puisse accéder à l’emplacement de magasin de données référencé par la référence de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367189787
        }
      },
      "outputs": [],
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
        "\n",
        "# Step 1, Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2, run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OK, vous êtes prêt à créer le pipeline à partir des étapes que vous avez définies, et à l’exécuter à titre d’essai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367288774
        },
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une représentation graphique de l’essai du pipeline s’affiche dans le widget lors de son exécution. Gardez un œil sur l’indicateur de noyau en haut à droite de la page. Quand il passe de **&#9899;** à **&#9711;**, l’exécution du code est terminée. Vous pouvez également surveiller les exécutions du pipeline dans la page **Essais** dans [Azure Machine Learning Studio](https://ml.azure.com).\n",
        "\n",
        "Une fois le pipeline terminé, vous pouvez examiner les métriques enregistrées par ses exécutions enfants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367294378
        }
      },
      "outputs": [],
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En supposant que le pipeline a réussi, un nouveau modèle devrait être inscrit avec l’étiquette *Contexte d’apprentissage* indiquant que son apprentissage a été effectué dans un pipeline. Exécutez le code suivant pour vérifier cela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367297400
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Publier le pipeline\n",
        "\n",
        "Une fois que vous avez créé et testé un pipeline, vous pouvez le publier en tant que service REST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367300325
        }
      },
      "outputs": [],
      "source": [
        "# Publish the pipeline from the run\n",
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notez que le pipeline publié possède un point de terminaison que vous pouvez voir dans la page **Points de terminaison** (sous l’onglet **Points de terminaison du pipeline**) dans [Azure Machine Learning studio](https://ml.azure.com). Vous pouvez également trouver son URI en tant que propriété de l’objet pipeline publié :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367303243
        }
      },
      "outputs": [],
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(rest_endpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appeler le point de terminaison du pipeline\n",
        "\n",
        "Pour utiliser le point de terminaison, les applications clientes doivent effectuer un appel REST sur HTTP. Cette demande devant être authentifiée, un en-tête d’autorisation est requis. Une application réelle nécessiterait un principal de service avec lequel s’authentifier mais, pour tester cela, nous allons utiliser l’en-tête d’autorisation de votre connexion actuelle à votre espace de travail Azure, que vous pouvez obtenir à l’aide du code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367306323
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()\n",
        "print(\"Authentication header ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous sommes maintenant prêts à appeler l’interface REST. Le pipeline s’exécutant de façon asynchrone, nous obtenons un identificateur en retour, que nous pouvons utiliser pour suivre l’essai de pipeline à mesure pendant son exécution :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367309225
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "experiment_name = 'mslearn-diabetes-pipeline'\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": experiment_name})\n",
        "run_id = response.json()[\"Id\"]\n",
        "run_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Étant donné que vous disposez de l’ID d’exécution, vous pouvez l’utiliser pour attendre la fin de l’exécution.\n",
        "\n",
        "> **Remarque** : le pipeline devrait se terminer rapidement, car chaque étape a été configurée pour permettre la réutilisation de la sortie. Cela a été fait principalement pour des raisons pratiques et pour gagner du temps dans ce cours. En réalité, vous souhaiterez probablement que la première étape s’exécute chaque fois que les données changent, et ne déclenche les étapes suivantes que si la sortie de la première étape change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367316814
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "published_pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Planifier le pipeline\n",
        "\n",
        "Supposons que la clinique pour patients atteints d’un diabète collecte de nouvelles données chaque semaine et les ajoute au jeu de données. Vous pouvez exécuter le pipeline chaque semaine pour ré-effectuer l’apprentissage du modèle avec les nouvelles données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367324073
        }
      },
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
        "\n",
        "# Submit the Pipeline every Monday at 00:00 UTC\n",
        "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
        "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
        "                                  description=\"Based on time\",\n",
        "                                  pipeline_id=published_pipeline.id, \n",
        "                                  experiment_name='mslearn-diabetes-pipeline', \n",
        "                                  recurrence=recurrence)\n",
        "print('Pipeline scheduled.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez récupérer les planifications définies dans l’espace de travail comme suit :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367327077
        }
      },
      "outputs": [],
      "source": [
        "schedules = Schedule.list(ws)\n",
        "schedules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vous pouvez vérifier la dernière exécution comme suit :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1649367330036
        }
      },
      "outputs": [],
      "source": [
        "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
        "latest_run = list(pipeline_experiment.get_runs())[0]\n",
        "\n",
        "latest_run.get_details()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il s’agit d’un exemple simple, conçu pour illustrer le principe. En réalité, vous pouvez créer une logique plus sophistiquée dans les étapes du pipeline, par exemple, en évaluant le modèle par rapport à des données de test afin de calculer une métrique de performance comme l’AUC ou la précision, en comparant la métrique à celle de versions précédemment inscrites du modèle et en inscrivant le nouveau modèle uniquement s’il fonctionne mieux.\n",
        "\n",
        "Vous pouvez utiliser l’[extension Azure Machine Learning pour Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) pour combiner des pipelines Azure ML avec des pipelines Azure DevOps (le fait qu’ils portent le même nom porte à confusion), et intégrer le ré-apprentissage du modèle dans un *processus d’intégration continue et livraison continue (CI/CD)* Par exemple, vous pourriez utiliser un pipeline *génération* Azure DevOps pour déclencher un pipeline Azure ML qui effectue l’apprentissage d’un modèle et l’inscrit. Ensuite, une fois le modèle inscrit, il pourrait déclencher un pipeline *mise en production* Azure Devops qui déploie le modèle en tant que service web, ainsi que l’application ou le service qui utilisent le modèle."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
